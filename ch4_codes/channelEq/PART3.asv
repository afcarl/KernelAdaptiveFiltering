%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%Copyright Weifeng Liu 
%CNEL
%July 1, 2008
%
%description:
%compare the performance of LMS1 APA1 SKLMS1 SKAPA1 SKAPA2 in channel
%equalization
%Abrupt change and reconvergence
%
%Usage:
%ch3, channel equalization, figures 3-9, 3-10
%
%Outside functions called or toolboxes used:
%LMS1s, APA1s, sparseKLMS1s, sparseKAPA1s, sparseKAPA2s
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

clear all,
close all
clc

%======filter config=======
%time delay (embedding) length
inputDimension = 3;
equalizationDelay = 0;
%Kernel parameters
typeKernel = 'Gauss';
paramKernel = .1;

%======end of config=======
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%       Parameters
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



flagLearningCurve = 1;

toleranceDistance = 0.05;
tolerancePredictError = 0.01;

stepSizeKlms1 = .15;
stepSizeWeightKlms1 = 0;
stepSizeBiasKlms1 = 0;

regularizationFactorKrls = 0.01;
forgettingFactorKrls = 1;
    
    
%data size
trainSize = 1500;
testSize = 100;

change_time = 500;
noise_std = 0.1;


%======end of data===========
%%    
MC = 100;
learningCurveLms1_en = zeros(trainSize,1);
ensembleLearningCurveKrls = zeros(trainSize,1);

disp([num2str(MC), '  Monte Carlo simulations. Please wait...'])
for mc = 1:MC
    disp(mc)
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%
	%       Data Formatting
	%
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	%=========data===============
	% Generate binary data
	u = sign(randn(1,trainSize*1.5));
	z = filter([1 0.5],1,u);
	% Channel noise
	ns = noise_std*randn(1,length(z));
	% Ouput of the nonlinear channel
	y = z - 0.9*z.^2 + ns;
    y(change_time:end) = 0.9*z(change_time:end).^2 - z(change_time:end) + ns(change_time:end);

	%data embedding
	trainInput = zeros(inputDimension,trainSize);
	for k=1:trainSize
		trainInput(:,k) = y(k:k+inputDimension-1)';
	end
	% Desired signal
	trainTarget = zeros(trainSize,1);
	for ii=1:trainSize
		trainTarget(ii) = u(equalizationDelay+ii);
	end % Generate binary data
	
	
    %======end of data===========

    %=========sparse Kernel LMS 1===================

    [expansionCoefficientKlms1,weightVectorKlms1,biasTermKlms1,learningCurveKlms1,dictionaryIndexKlms1,netSizeKlms1] = ...
        sparseKLMS1s(trainInput,trainTarget,typeKernel,paramKernel,...
        stepSizeKlms1,stepSizeWeightKlms1,stepSizeBiasKlms1,toleranceDistance,tolerancePredictError,flagLearningCurve);
    learningCurveKlms1_en = learningCurveKlms1_en + learningCurveKlms1;
    %=========end of sparse Kernel LMS================
    
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %
    %              KRLS
    %
    %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

    [expansionCoefficientKrls,learningCurveKrls] = ...
        KRLS(trainInput,trainTarget,typeKernel,paramKernel,regularizationFactorKrls,forgettingFactorKrls);
    ensembleLearningCurveKrls = ensembleLearningCurveKrls + learningCurveKrls;
    % =========end of KRLS================
    
    %%
end%mc

%%
lineWid = 3;
if flagLearningCurve
	figure,
    hold on
	plot(learningCurveKlms1_en/MC,'b-','LineWidth', lineWid)

	plot(ensembleLearningCurveKrls/MC,'r-.','LineWidth', lineWid)
	hold off
	legend('APA-1','KLMS-NC','KAPA-2-NC')
    set(gca, 'FontSize', 14);
    set(gca, 'FontName', 'Arial');
    xlabel('iteration'),ylabel('MSE')
    grid on
end

figure,
plot(netSizeKlms1,'b-','LineWidth', lineWid)
hold on
%plot(netSizeKapa1,'g:','LineWidth', lineWid)
plot(netSizeKapa2,'r--','LineWidth', lineWid)
hold off
legend('KLMS-NC','KAPA-2-NC')
set(gca, 'FontSize', 14);
set(gca, 'FontName', 'Arial');
xlabel('iteration'),ylabel('network size')
grid on
